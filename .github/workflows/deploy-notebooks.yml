name: db1-main

on:
  workflow_call:
    inputs:
      dbx-env:
        required: true
        type: string
      resourceGroupName:
        required: true
        type: string
      notebooksPath:
        required: true
        type: string
    secrets:
      AZURE_CLIENT_ID:
        required: true
      AZURE_TENANT_ID:
        required: true
      DATABRICKS_HOST:
        required: true
      DATABRICKS_TOKEN:
        required: true


permissions:
  id-token: write
  contents: read

jobs:
  deploy-notebooks:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: "3be2ce56-4a5f-4034-88d7-2953d1819ed3"

      - name: Configure Azure CLI
        run: |
          az config set extension.use_dynamic_install=yes_without_prompt
          az config set extension.dynamic_install_allow_preview=true

      # - name: Install Databricks CLI
      #   run: |
      #     pip install databricks-cli
      - uses: databricks/setup-cli@main

      - name: Configure Databricks CLI
        run: |
          databricks configure --token <<EOF
          ${{ secrets.DATABRICKS_HOST }}
          ${{ secrets.DATABRICKS_TOKEN }}
          EOF

      - name: Deploy Databricks Notebooks
        run: |
          echo "Deploying notebooks to ${{ inputs.dbx-env }} environment"
          echo "Using resource group: ${{ inputs.resourceGroupName }}"
          echo "Notebooks path: ${{ inputs.notebooksPath }}"

          # Deploy the notebooks using Databricks CLI
          databricks workspace import_dir \
            --overwrite \
            ${{ inputs.notebooksPath }} \
            /live
          # https://endjin.com/blog/2019/09/import-and-export-notebooks-in-databricks

          echo "Deployment complete."
        shell: /usr/bin/bash -e {0}