trigger:
    - main
    - addbasicdbxws
    - cgpersonal

variables:
  - template: .\env-variables.yml
  - name: notebooksPath
    value: "dbx-using-cicdtools-azdevops/notebooks"


pool:
  vmImage: 'ubuntu-latest'

# pool:
#   name: 'fiftysix-agents-devops' # Specify the agent pool name
#   demands:
#     - Agent.Name -equals vm-fiftysix0=-agent1 # Target the specific agent

stages:
 - stage: DoingDev
   variables:
     - group: Dev-vars
      # Deploy Notebooks
   jobs: 
     - template: templates/dbrickscli.yml
       parameters:
         stageId: "Deploy_to_Dev_Environment"
         env: "dev"
         environmentName: ${{ variables['dev-environment-name'] }}
         serviceConnection: ${{ variables['dev-service-connection-name'] }}
         notebooksPath: $(notebooksPath)
         databricksHost: ${{ variables['dev-databricks-host'] }}
         databricksClientId: ${{ variables['dev-databricks-clientid'] }}
         databricksClientSecret: $(databrickstoken-appreg-srvcondevops-dev) # from azure devops pipeline library (-group Dev-vars (see above)), which is connected to azure key vault, but you can also use a secret variable from the pipeline library
         databricksAccountID: ${{ variables['dev-databricks-sp-accountid'] }}

#  - stage: DoingProd
#    dependsOn: DoingDev  # Ensures PROD runs only after DEV succeeds
#    variables:
#      - group: Prod-vars
#    jobs:
#     - template: templates/dbrickscli.yml
#       parameters:
#         stageId: "Deploy_to_PROD_Environment"
#         env: "prod"
#         environmentName: ${{ variables['prod-environment-name'] }}
#         resourceGroupName: ${{ variables['prod-resource-group-name'] }}
#         serviceConnection: ${{ variables['prod-service-connection-name'] }}
#         notebooksPath: $(notebooksPath)
#         databricksHost: ${{ variables['prod-databricks-host'] }}
#         databricksToken: ${{ variables['databrickstoken-appreg-srvcondevops-dev'] }}
